# # #import the required libraries
# # import pathlib
# # import os

# # import numpy as np
# # import pandas as pd
# # import matplotlib.pyplot as plt

# # import PIL

# # import tensorflow as tf
# # from tensorflow import keras
# # from tensorflow.keras import layers
# # from tensorflow.keras.models import Sequential

# # from tensorflow.keras.optimizers import Adam
# # from tensorflow.keras.callbacks import ModelCheckpoint,EarlyStopping

# # # from keras.preprocessing.image import load_img

# # # Defining the path for train and test images
# # data_dir_train = pathlib.Path("data/Train/")
# # data_dir_test = pathlib.Path("data/Test/")


# # # Count the number of image in Train and Test directory
# # # Using the glob to retrieve files/pathnames matching a specified pattern.

# # #Train Image count
# # image_count_train = len(list(data_dir_train.glob('*/*.jpg')))
# # print(image_count_train)

# # #Test Image count
# # image_count_test = len(list(data_dir_test.glob('*/*.jpg')))
# # print(image_count_test)


# # #Visualize one instance of all the class present in the dataset.

# # #image_dataset_from_directory() will return a tf.data.Dataset that yields batches of images from the subdirectories.
# # #label_mode is categorial, the labels are a float32 tensor of shape (batch_size, num_classes), representing a one-hot encoding of the class index.
# # image_dataset = tf.keras.preprocessing.image_dataset_from_directory(data_dir_train,batch_size=32,image_size=(180,180),
# #                                                                     label_mode='categorical',seed=123)

# # #all the classes of Skin Cancer
# # class_names = image_dataset.class_names

# # #Dictionary to store the path of image as per the class
# # files_path_dict = {}

# # for c in class_names:
# #     files_path_dict[c] = list(map(lambda x:str(data_dir_train)+'/'+c+'/'+x,os.listdir(str(data_dir_train)+'/'+c)))
    
# # #Visualize image 
# # plt.figure(figsize=(15,15))
# # index = 0
# # # for c in class_names:
# # #     path_list = files_path_dict[c][:1]
# # #     index += 1
# # #     plt.subplot(3,3,index)
# # #     plt.imshow(load_img(path_list[0],target_size=(180,180)))
# # #     plt.title(c)
# # #     plt.axis("off")
    
# # def class_distribution_count(directory):
    
# #     #count number of image in each classes
# #     count= []
# #     for path in pathlib.Path(directory).iterdir():
# #         if path.is_dir():
# #             count.append(len([name for name in os.listdir(path)
# #                                if os.path.isfile(os.path.join(path, name))]))
    
# #     #name of the classes
# #     sub_directory = [name for name in os.listdir(directory)
# #                     if os.path.isdir(os.path.join(directory, name))]
    
# #     #return dataframe with image count and class.
# #     return pd.DataFrame(list(zip(sub_directory,count)),columns =['Class', 'No. of Image'])

# # df = class_distribution_count(data_dir_train)


# # path_to_training_dataset="data/Train/"
# # import Augmentor
# # for i in class_names:
# #     p = Augmentor.Pipeline(path_to_training_dataset + i)
# #     p.rotate(probability=0.7, max_left_rotation=10, max_right_rotation=10)
# #     p.sample(500)  #Adding 500 samples per class to make sure that none of the classes are sparse
    
# # #Count total number of image generated by Augmentor.
# # image_count_train = len(list(data_dir_train.glob('*/output/*.jpg')))
# # print(image_count_train)


# # # train dataset 
# # train_ds = tf.keras.preprocessing.image_dataset_from_directory(data_dir_train, batch_size=32,
# #                                                                image_size=(180,180), label_mode='categorical',
# #                                                                seed=123,subset="training",
# #                                                                validation_split=0.2)

# # #label_mode is categorial, the labels are a float32 tensor of shape (batch_size, num_classes),
# # #representing a one-hot encoding of the class index.


# # # validation dataset 
# # val_ds =tf.keras.preprocessing.image_dataset_from_directory(data_dir_train,batch_size=32,
# #                                                             image_size=(180,180), label_mode='categorical',
# #                                                             seed=123,subset="validation",
# #                                                             validation_split=0.2)

# # #tf.data.experimental.AUTOTUNE defines appropriate number of processes that are free for working.

# # #`Dataset.cache()` keeps the images in memory after they're loaded off disk during the first epoch.

# # #`Dataset.prefetch()` overlaps data preprocessing and model execution while training.


# # AUTOTUNE = tf.data.experimental.AUTOTUNE
# # train_ds = train_ds.cache().shuffle(1000).prefetch(buffer_size=AUTOTUNE)
# # val_ds = val_ds.cache().prefetch(buffer_size=AUTOTUNE)


# # #CNN Model Architecture

# # #Sequential allows you to create models layer-by-layer  
# # model = Sequential()

# # model.add(layers.Rescaling(1./255,input_shape=(180,180,3)))   #Rescaling Layer

# # #First Convulation layer
# # model.add(layers.Conv2D(32,kernel_size=(3,3),activation='relu'))
# # model.add(layers.MaxPool2D(pool_size=(2,2)))

# # #Second Convulation Layer
# # model.add(layers.Conv2D(64,kernel_size=(3,3),activation='relu'))
# # model.add(layers.MaxPool2D(pool_size=(2,2)))

# # #Third Convulation Layer
# # model.add(layers.Conv2D(128,kernel_size=(3,3),activation='relu'))
# # model.add(layers.MaxPool2D(pool_size=(2,2)))

# # #Dropout layer with 50% Fraction of the input units to drop.
# # model.add(layers.Dropout(0.5))

# # #Flatten Layer
# # ##Keras.layers.flatten function flattens the multi-dimensional input tensors into a single dimension.
# # model.add(layers.Flatten())

# # #Dense Layer
# # model.add(layers.Dense(128,activation='relu'))

# # #Dropout layer with 25% Fraction of the input units to drop.
# # model.add(layers.Dropout(0.25))

# # #Dense Layer with softmax activation function.
# # #Softmax is an activation function that scales numbers/logits into probabilities.
# # model.add(layers.Dense(len(class_names),activation='softmax'))

# # model.summary()


# # #Compile the Model

# # #Adam optimization: is a stochastic gradient descent method that is based on adaptive estimation of first-order and second-order moments.
# # #categorical_crossentropy: Used as a loss function for multi-class classification model where there are two or more output labels.

# # model.compile(optimizer="Adam",loss="categorical_crossentropy",metrics=["accuracy"])

# # #ModelCheckpoint callback is used in conjunction with training using model.fit() to save a model or weights (in a checkpoint file) at some interval,
# # #so the model or weights can be loaded later to continue the training from the state saved.
# # # checkpoint = ModelCheckpoint("model.h5",monitor="val_accuracy",save_best_only=True,mode="auto",verbose=1)

# # #Stop training when a monitored metric has stopped improving.
# # # earlystop = EarlyStopping(monitor="val_accuracy",patience=5,mode="auto",verbose=1)


# # # Train the model
# # epochs = 20
# # history = model.fit(train_ds, validation_data=val_ds, epochs=epochs)


# # # Plot the training curves

# # # epochs_range = range(earlystop.stopped_epoch+1)

# # plt.figure(figsize=(15, 10))
# # plt.subplot(1, 2, 1)

# # #Plot Model Accuracy
# # plt.plot(history.history['accuracy'])
# # plt.plot(history.history['val_accuracy'])
# # plt.title('model accuracy')
# # plt.ylabel('accuracy')
# # # plt.xlabel(epochs_range)
# # plt.legend(['train', 'val'], loc='upper left')

# # #Plot Model Loss
# # plt.subplot(1, 2, 2)
# # plt.plot(history.history['loss'])
# # plt.plot(history.history['val_loss'])
# # plt.title('model loss')
# # plt.ylabel('loss')
# # # plt.xlabel(epochs_range)
# # plt.legend(['train', 'val'], loc='upper left')
# # plt.show()



# # from glob import glob
# # Test_image_path = os.path.join(data_dir_test, class_names[1], '*')
# # Test_image = glob(Test_image_path)
# # # Test_image = load_img(Test_image[-1],target_size=(180,180,3))
# # # plt.imshow(Test_image)
# # # plt.grid(False)

# # img = np.expand_dims(Test_image,axis=0)
# # pred = model.predict(img)
# # pred = np.argmax(pred)
# # pred_class = class_names[pred]
# # print("Actual Class "+ class_names[1] +'\n'+ "Predictive Class "+pred_class )


# import pathlib
# import os
# import numpy as np
# import pandas as pd
# import matplotlib.pyplot as plt
# import PIL
# import tensorflow as tf
# from tensorflow import keras
# from tensorflow.keras import layers
# from tensorflow.keras.models import Sequential
# from tensorflow.keras.optimizers import Adam
# from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping
# from tensorflow.keras.preprocessing import image
# from glob import glob
# import Augmentor

# # Defining the path for train and test images
# data_dir_train = pathlib.Path("data/Train/")
# data_dir_test = pathlib.Path("data/Test/")

# # Count the number of image in Train and Test directory
# image_count_train = len(list(data_dir_train.glob('*/*.jpg')))
# print(image_count_train)

# image_count_test = len(list(data_dir_test.glob('*/*.jpg')))
# print(image_count_test)

# # Visualize one instance of all the classes present in the dataset
# image_dataset = tf.keras.preprocessing.image_dataset_from_directory(data_dir_train,
#                                                                     batch_size=32,
#                                                                     image_size=(180,180),
#                                                                     label_mode='categorical',
#                                                                     seed=123)

# class_names = image_dataset.class_names

# # Dictionary to store the path of image as per the class
# files_path_dict = {}
# for c in class_names:
#     files_path_dict[c] = list(map(lambda x: str(data_dir_train)+'/'+c+'/'+x, os.listdir(str(data_dir_train)+'/'+c)))

# # Visualize images
# plt.figure(figsize=(15,15))
# index = 0
# for c in class_names:
#     path_list = files_path_dict[c][:1]
#     index += 1
#     plt.subplot(3, 3, index)
#     plt.imshow(PIL.Image.open(path_list[0]).resize((180, 180)))
#     plt.title(c)
#     plt.axis("off")

# # Count number of images in each class
# def class_distribution_count(directory):
#     count = []
#     for path in pathlib.Path(directory).iterdir():
#         if path.is_dir():
#             count.append(len([name for name in os.listdir(path) if os.path.isfile(os.path.join(path, name))]))
    
#     sub_directory = [name for name in os.listdir(directory) if os.path.isdir(os.path.join(directory, name))]
#     return pd.DataFrame(list(zip(sub_directory, count)), columns=['Class', 'No. of Image'])

# df = class_distribution_count(data_dir_train)

# # Augmenting the dataset using Augmentor
# path_to_training_dataset = "data/Train/"
# for i in class_names:
#     p = Augmentor.Pipeline(path_to_training_dataset + i)
#     p.rotate(probability=0.7, max_left_rotation=10, max_right_rotation=10)
#     p.sample(500)  # Adding 500 samples per class

# # Count total number of image generated by Augmentor
# image_count_train = len(list(data_dir_train.glob('*/output/*.jpg')))
# print(image_count_train)

# # Train dataset
# train_ds = tf.keras.preprocessing.image_dataset_from_directory(data_dir_train, 
#                                                                batch_size=32,
#                                                                image_size=(180, 180), 
#                                                                label_mode='categorical',
#                                                                seed=123,
#                                                                subset="training",
#                                                                validation_split=0.2)

# # Validation dataset
# val_ds = tf.keras.preprocessing.image_dataset_from_directory(data_dir_train, 
#                                                              batch_size=32,
#                                                              image_size=(180, 180), 
#                                                              label_mode='categorical',
#                                                              seed=123,
#                                                              subset="validation",
#                                                              validation_split=0.2)

# # Cache and prefetch datasets
# AUTOTUNE = tf.data.experimental.AUTOTUNE
# train_ds = train_ds.cache().shuffle(1000).prefetch(buffer_size=AUTOTUNE)
# val_ds = val_ds.cache().prefetch(buffer_size=AUTOTUNE)

# # CNN Model Architecture
# model = Sequential()
# model.add(layers.Rescaling(1./255, input_shape=(180,180,3)))  # Rescaling Layer

# # First Convolution Layer
# model.add(layers.Conv2D(32, kernel_size=(3,3), activation='relu'))
# model.add(layers.MaxPool2D(pool_size=(2,2)))

# # Second Convolution Layer
# model.add(layers.Conv2D(64, kernel_size=(3,3), activation='relu'))
# model.add(layers.MaxPool2D(pool_size=(2,2)))

# # Third Convolution Layer
# model.add(layers.Conv2D(128, kernel_size=(3,3), activation='relu'))
# model.add(layers.MaxPool2D(pool_size=(2,2)))

# # Dropout Layer
# model.add(layers.Dropout(0.5))

# # Flatten Layer
# model.add(layers.Flatten())

# # Dense Layer
# model.add(layers.Dense(128, activation='relu'))

# # Dropout Layer
# model.add(layers.Dropout(0.25))

# # Final Dense Layer with softmax
# model.add(layers.Dense(len(class_names), activation='softmax'))

# model.summary()

# # Compile the Model
# model.compile(optimizer="Adam", loss="categorical_crossentropy", metrics=["accuracy"])

# # Train the model
# epochs = 20
# history = model.fit(train_ds, validation_data=val_ds, epochs=epochs)

# # Plot the training curves
# plt.figure(figsize=(15, 10))
# plt.subplot(1, 2, 1)
# plt.plot(history.history['accuracy'])
# plt.plot(history.history['val_accuracy'])
# plt.title('Model Accuracy')
# plt.ylabel('Accuracy')
# plt.legend(['Train', 'Validation'], loc='upper left')

# plt.subplot(1, 2, 2)
# plt.plot(history.history['loss'])
# plt.plot(history.history['val_loss'])
# plt.title('Model Loss')
# plt.ylabel('Loss')
# plt.legend(['Train', 'Validation'], loc='upper left')
# plt.show()

# # Prediction on Test Image
# Test_image_path = os.path.join(data_dir_test, class_names[1], '*')
# Test_image = glob(Test_image_path)
# img = image.load_img(Test_image[-1], target_size=(180, 180))
# img_array = np.expand_dims(image.img_to_array(img), axis=0) / 255.0  # Normalize

# pred = model.predict(img_array)
# pred_class = class_names[np.argmax(pred)]
# print(f"Actual Class: {class_names[1]} \nPredicted Class: {pred_class}")



# Import the required libraries
import pathlib
import os
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import PIL
import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
from tensorflow.keras.models import Sequential
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping
from glob import glob

# Defining the path for train and test images
data_dir_train = pathlib.Path("data/Train/")
data_dir_test = pathlib.Path("data/Test/")

# Count the number of image in Train and Test directory
image_count_train = len(list(data_dir_train.glob('*/*.jpg')))
print(image_count_train)

image_count_test = len(list(data_dir_test.glob('*/*.jpg')))
print(image_count_test)

# Visualize one instance of all the class present in the dataset
image_dataset = tf.keras.preprocessing.image_dataset_from_directory(
    data_dir_train, 
    batch_size=32,
    image_size=(180, 180),
    label_mode='categorical',
    seed=123
)

class_names = image_dataset.class_names

# Dictionary to store the path of images as per the class
files_path_dict = {}
for c in class_names:
    files_path_dict[c] = list(map(lambda x: str(data_dir_train) + '/' + c + '/' + x, os.listdir(str(data_dir_train) + '/' + c)))

# Visualize image
plt.figure(figsize=(15, 15))
index = 0
# Display some images (optional)
# for c in class_names:
#     path_list = files_path_dict[c][:1]
#     index += 1
#     plt.subplot(3, 3, index)
#     plt.imshow(load_img(path_list[0], target_size=(180, 180)))
#     plt.title(c)
#     plt.axis("off")

# Function to count the distribution of images in each class
def class_distribution_count(directory):
    count = []
    for path in pathlib.Path(directory).iterdir():
        if path.is_dir():
            count.append(len([name for name in os.listdir(path) if os.path.isfile(os.path.join(path, name))]))
    sub_directory = [name for name in os.listdir(directory) if os.path.isdir(os.path.join(directory, name))]
    return pd.DataFrame(list(zip(sub_directory, count)), columns=['Class', 'No. of Image'])

df = class_distribution_count(data_dir_train)

# Data augmentation using Augmentor (optional)
import Augmentor
path_to_training_dataset = "data/Train/"
for i in class_names:
    p = Augmentor.Pipeline(path_to_training_dataset + i)
    p.rotate(probability=0.7, max_left_rotation=10, max_right_rotation=10)
    p.sample(500)  # Adding 500 samples per class to make sure none of the classes are sparse

# Count total number of image generated by Augmentor
image_count_train = len(list(data_dir_train.glob('*/output/*.jpg')))
print(image_count_train)

# Train dataset with smaller shuffle buffer size and batch size for memory optimization
AUTOTUNE = tf.data.experimental.AUTOTUNE

train_ds = tf.keras.preprocessing.image_dataset_from_directory(
    data_dir_train, 
    batch_size=16,  # Reduced batch size to fit memory
    image_size=(180, 180),
    label_mode='categorical',
    seed=123,
    subset="training",
    validation_split=0.2
)

val_ds = tf.keras.preprocessing.image_dataset_from_directory(
    data_dir_train, 
    batch_size=16,  # Reduced batch size to fit memory
    image_size=(180, 180),
    label_mode='categorical',
    seed=123,
    subset="validation",
    validation_split=0.2
)

train_ds = train_ds.cache().shuffle(500).prefetch(buffer_size=AUTOTUNE)  # Reduced shuffle buffer size
val_ds = val_ds.cache().prefetch(buffer_size=AUTOTUNE)

# CNN Model Architecture
model = Sequential()

model.add(layers.Rescaling(1./255, input_shape=(180, 180, 3)))  # Rescaling Layer
model.add(layers.Conv2D(32, kernel_size=(3, 3), activation='relu'))
model.add(layers.MaxPool2D(pool_size=(2, 2)))
model.add(layers.Conv2D(64, kernel_size=(3, 3), activation='relu'))
model.add(layers.MaxPool2D(pool_size=(2, 2)))
model.add(layers.Conv2D(128, kernel_size=(3, 3), activation='relu'))
model.add(layers.MaxPool2D(pool_size=(2, 2)))
model.add(layers.Dropout(0.5))
model.add(layers.Flatten())
model.add(layers.Dense(128, activation='relu'))
model.add(layers.Dropout(0.25))
model.add(layers.Dense(len(class_names), activation='softmax'))

model.summary()

# Compile the Model
model.compile(optimizer="Adam", loss="categorical_crossentropy", metrics=["accuracy"])

# Train the model with a reduced number of epochs for debugging (optional)
epochs = 10
history = model.fit(train_ds, validation_data=val_ds, epochs=epochs)

# Plot the training curves
plt.figure(figsize=(15, 10))
plt.subplot(1, 2, 1)
plt.plot(history.history['accuracy'])
plt.plot(history.history['val_accuracy'])
plt.title('Model Accuracy')
plt.ylabel('Accuracy')
plt.legend(['Train', 'Val'], loc='upper left')

plt.subplot(1, 2, 2)
plt.plot(history.history['loss'])
plt.plot(history.history['val_loss'])
plt.title('Model Loss')
plt.ylabel('Loss')
plt.legend(['Train', 'Val'], loc='upper left')
plt.show()

# Testing
Test_image_path = os.path.join(data_dir_test, class_names[1], '*')
Test_image = glob(Test_image_path)
img = np.expand_dims(Test_image, axis=0)
pred = model.predict(img)
pred = np.argmax(pred)
pred_class = class_names[pred]
print(f"Actual Class: {class_names[1]}")
print(f"Predicted Class: {pred_class}")
